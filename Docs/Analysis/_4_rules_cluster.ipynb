{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "import pandas as pd\n",
    "from SynTemp.SynUtils.utils import load_database, save_database\n",
    "data = pd.DataFrame(load_database('../../Data/DPO/USPTO_50K/USPTO_50K_aam_reactions.json.gz'))\n",
    "original_data = pd.read_csv('../../Data/USPTO_50K/USPTO_50K_original.csv')\n",
    "\n",
    "data = pd.concat([data, original_data['class']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data, random_state=42, stratify=data['class'], test_size=0.2)\n",
    "\n",
    "save_database(train.to_dict('records'), '../../Data/DPO/USPTO_50K/train.json.gz')\n",
    "save_database(test.to_dict('records'), '../../Data/DPO/USPTO_50K/test.json.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Hydrogen adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SynTemp.SynUtils.utils import load_from_pickle\n",
    "data = load_from_pickle('../../Data/DPO/USPTO_50K/Hydrogen/USPTO_50K_its_graph_rules_cluster.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SynTemp.SynUtils.utils import stratified_random_sample\n",
    "samples = stratified_random_sample(data, 'naive_cluster', 1, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reaction Type\n",
       "Single Cyclic     119\n",
       "Acyclic            60\n",
       "None               57\n",
       "Complex Cyclic     31\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(samples)['Reaction Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R-id': 31123,\n",
       " 'ITSGraph': (<networkx.classes.graph.Graph at 0x7fc5d070ee90>,\n",
       "  <networkx.classes.graph.Graph at 0x7fc5d071d490>,\n",
       "  <networkx.classes.graph.Graph at 0x7fc5d071fa10>),\n",
       " 'GraphRules': (<networkx.classes.graph.Graph at 0x7fc5d0730a10>,\n",
       "  <networkx.classes.graph.Graph at 0x7fc5d0730e50>,\n",
       "  <networkx.classes.graph.Graph at 0x7fc5d0731290>),\n",
       " 'naive_cluster': 0,\n",
       " 'Reaction Type': 'Single Cyclic',\n",
       " 'Rings': [4]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SynTemp.SynUtils.utils import stratified_random_sample\n",
    "\n",
    "samples = stratified_random_sample(data, 'naive_cluster', 1, 42)\n",
    "samples_good = [value for value in samples if value['Reaction Type'] in ['Single Cyclic', 'Complex Cyclic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done 220 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 267 out of 267 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "from SynTemp.SynRule.rule_writing import RuleWriting\n",
    "rules = RuleWriting.auto_extraction(data_dicts=samples, id_column='naive_cluster',\n",
    "                                    save_path='../../Data/DPO/USPTO_50K/Hydrogen/Rules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done 205 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 267 out of 267 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "from SynTemp.SynRule.rule_writing import RuleWriting\n",
    "rules_good = RuleWriting.auto_extraction(data_dicts=samples, id_column='naive_cluster',\n",
    "                                    save_path='../../Data/DPO/USPTO_50K/Hydrogen/Rules_good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SynTemp.SynRule.rule_benchmark import RuleBenchmark\n",
    "from SynTemp.SynChemistry.sf_similarity import SFSimilarity\n",
    "from SynTemp.SynChemistry.sf_maxfrag import SFMaxFrag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "logging.basicConfig(filename=f'../../Data/DPO/USPTO_50K/Hydrogen/topk_accuracy_good.log', level=logging.INFO, format='%(asctime)s - %(message)s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters for the experiment\n",
    "top_k_values = [1, 3, 5, 10]\n",
    "scoring_functions = {\n",
    "    'MaxFrag': SFMaxFrag(),\n",
    "    'ECFP6': SFSimilarity([\"ECFP6\"]),\n",
    "    'MACCS': SFSimilarity([\"MACCS\"]),\n",
    "    'RDK7': SFSimilarity([\"RDK7\"])\n",
    "}\n",
    "\n",
    "# Prepare DataFrame to store results\n",
    "    results_list = []\n",
    "\n",
    "# Run benchmark for each scoring function and Top K\n",
    "fw, bw = RuleBenchmark.reproduce_reactions(\n",
    "    database=database,\n",
    "    id_col=\"R-id\",\n",
    "    rule_file_path=f\"{root_dir}/Data/DPO/uspto/Rule\",\n",
    "    original_rsmi_col=\"reactions\",\n",
    "    repeat_times=1,\n",
    "    prior=False,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "root_dir = Path(__file__).parents[2]\n",
    "sys.path.append(str(root_dir))\n",
    "from SynTemp.SynUtils.utils import load_database\n",
    "from SynTemp.SynRule.rule_benchmark import RuleBenchmark\n",
    "from SynTemp.SynChemistry.sf_similarity import SFSimilarity\n",
    "from SynTemp.SynChemistry.sf_maxfrag import SFMaxFrag\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import logging\n",
    "    import pandas as pd\n",
    "\n",
    "    # Set up logging\n",
    "    logging.basicConfig(filename=f'{root_dir}/Docs/Notebook/topk_accuracy.log', level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "    # Load the database\n",
    "    database = load_database(f\"{root_dir}/Data/DPO/uspto/demo_database.json.gz\")\n",
    "\n",
    "    # Set the parameters for the experiment\n",
    "    top_k_values = [1, 3, 5, 10]\n",
    "    scoring_functions = {\n",
    "        'MaxFrag': SFMaxFrag(),\n",
    "        'ECFP6': SFSimilarity([\"ECFP6\"]),\n",
    "        'MACCS': SFSimilarity([\"MACCS\"]),\n",
    "        'RDK7': SFSimilarity([\"RDK7\"])\n",
    "    }\n",
    "\n",
    "    # Prepare DataFrame to store results\n",
    "    results_list = []\n",
    "\n",
    "    # Run benchmark for each scoring function and Top K\n",
    "    fw, bw = RuleBenchmark.reproduce_reactions(\n",
    "        database=database,\n",
    "        id_col=\"R-id\",\n",
    "        rule_file_path=f\"{root_dir}/Data/DPO/uspto/Rule\",\n",
    "        original_rsmi_col=\"reactions\",\n",
    "        repeat_times=1,\n",
    "        prior=False,\n",
    "    )\n",
    "\n",
    "    for name, func in scoring_functions.items():\n",
    "        for k in top_k_values:\n",
    "            accuracy = RuleBenchmark.TopKAccuracy(\n",
    "                fw,\n",
    "                \"reactions\",\n",
    "                \"ranked_reactions\",\n",
    "                k,\n",
    "                ignore_stero=True,\n",
    "                scoring_function=func,\n",
    "            )\n",
    "            log_message = f\"Top {k} accuracy for {name}: {accuracy}\"\n",
    "            print(log_message)\n",
    "            logging.info(log_message)\n",
    "            \n",
    "            # Append results to the list\n",
    "            results_list.append({'Scoring Function': name, 'Top K': f'Top {k}', 'Accuracy': accuracy})\n",
    "\n",
    "    # Convert list to DataFrame\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "\n",
    "    # Pivot the DataFrame to get the desired layout\n",
    "    pivot_df = results_df.pivot(index='Scoring Function', columns='Top K', values='Accuracy')\n",
    "\n",
    "    # # Save results to CSV\n",
    "    # pivot_df.to_csv('topk_accuracy_matrix.csv')\n",
    "    # logging.info(\"Results matrix saved to topk_accuracy_matrix.csv\")\n",
    "\n",
    "    # Log the pivot table\n",
    "    pivot_log = pivot_df.to_string()\n",
    "    logging.info(\"Results Matrix:\\n\" + pivot_log)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SynITSG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
