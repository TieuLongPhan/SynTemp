{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "import pandas as pd\n",
    "from SynTemp.SynUtils.utils import load_database, save_database, load_from_pickle\n",
    "\n",
    "nh_r0_fw = load_database('../../Data/DPO/USPTO_50K/Non_hydrogen/Output/fw_0.json.gz')\n",
    "nh_r0_bw = load_database('../../Data/DPO/USPTO_50K/Non_hydrogen/Output/bw_0.json.gz')\n",
    "nh_r1_fw = load_database('../../Data/DPO/USPTO_50K/Non_hydrogen/Output/fw_1.json.gz')\n",
    "nh_r1_bw = load_database('../../Data/DPO/USPTO_50K/Non_hydrogen/Output/bw_1.json.gz')\n",
    "nh_r2_fw = load_database('../../Data/DPO/USPTO_50K/Non_hydrogen/Output/fw_2.json.gz')\n",
    "nh_r2_bw = load_database('../../Data/DPO/USPTO_50K/Non_hydrogen/Output/bw_2.json.gz')\n",
    "nh_r3_fw = load_database('../../Data/DPO/USPTO_50K/Non_hydrogen/Output/fw_3.json.gz')\n",
    "nh_r3_bw = load_database('../../Data/DPO/USPTO_50K/Non_hydrogen/Output/bw_3.json.gz')\n",
    "\n",
    "h_r0_fw = load_database('../../Data/DPO/USPTO_50K/Hydrogen/Output/fw_0.json.gz')\n",
    "h_r0_bw = load_database('../../Data/DPO/USPTO_50K/Hydrogen/Output/bw_0.json.gz')\n",
    "h_r1_fw = load_database('../../Data/DPO/USPTO_50K/Hydrogen/Output/fw_1.json.gz')\n",
    "h_r1_bw = load_database('../../Data/DPO/USPTO_50K/Hydrogen/Output/bw_1.json.gz')\n",
    "h_r2_fw = load_database('../../Data/DPO/USPTO_50K/Hydrogen/Output/fw_2.json.gz')\n",
    "h_r2_bw = load_database('../../Data/DPO/USPTO_50K/Hydrogen/Output/bw_2.json.gz')\n",
    "h_r3_fw = load_database('../../Data/DPO/USPTO_50K/Hydrogen/Output/fw_3.json.gz')\n",
    "h_r3_bw = load_database('../../Data/DPO/USPTO_50K/Hydrogen/Output/bw_3.json.gz')\n",
    "\n",
    "gh_r0_fw = load_database('../../Data/DPO/USPTO_50K/Good_hydrogen/Output/fw_0.json.gz')\n",
    "gh_r0_bw = load_database('../../Data/DPO/USPTO_50K/Good_hydrogen/Output/bw_0.json.gz')\n",
    "gh_r1_fw = load_database('../../Data/DPO/USPTO_50K/Good_hydrogen/Output/fw_1.json.gz')\n",
    "gh_r1_bw = load_database('../../Data/DPO/USPTO_50K/Good_hydrogen/Output/bw_1.json.gz')\n",
    "gh_r2_fw = load_database('../../Data/DPO/USPTO_50K/Good_hydrogen/Output/fw_2.json.gz')\n",
    "gh_r2_bw = load_database('../../Data/DPO/USPTO_50K/Good_hydrogen/Output/bw_2.json.gz')\n",
    "gh_r3_fw = load_database('../../Data/DPO/USPTO_50K/Good_hydrogen/Output/fw_3.json.gz')\n",
    "gh_r3_bw = load_database('../../Data/DPO/USPTO_50K/Good_hydrogen/Output/bw_3.json.gz')\n",
    "\n",
    "\n",
    "\n",
    "hier_r0_fw = load_database('../../Data/DPO/USPTO_50K/Good_hydrogen/Output/fw_hier_0.json.gz')\n",
    "hier_r0_bw = load_database('../../Data/DPO/USPTO_50K/Good_hydrogen/Output/bw_hier_0.json.gz')\n",
    "hier_r1_fw = load_database('../../Data/DPO/USPTO_50K/Good_hydrogen/Output/fw_hier_1.json.gz')\n",
    "hier_r1_bw = load_database('../../Data/DPO/USPTO_50K/Good_hydrogen/Output/bw_hier_1.json.gz')\n",
    "hier_r2_fw = load_database('../../Data/DPO/USPTO_50K/Good_hydrogen/Output/fw_hier_2.json.gz')\n",
    "hier_r2_bw = load_database('../../Data/DPO/USPTO_50K/Good_hydrogen/Output/bw_hier_2.json.gz')\n",
    "hier_r3_fw = load_database('../../Data/DPO/USPTO_50K/Good_hydrogen/Output/fw_hier_3.json.gz')\n",
    "hier_r3_bw = load_database('../../Data/DPO/USPTO_50K/Good_hydrogen/Output/bw_hier_3.json.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Coverage analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "\n",
    "def reconstruction_rate_solutions(data: List[Dict], solutions_column: str = 'unrank', positive_columns: str = 'positive_reactions') -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Calculate the reconstruction rate and coverage rate for solutions in the data.\n",
    "\n",
    "    Parameters:\n",
    "    - data: List of dictionaries containing the data.\n",
    "    - solutions_column: The key in the dictionaries representing the solutions. Default is 'unrank'.\n",
    "    - positive_columns: The key in the dictionaries representing the positive reactions. Default is 'positive_reactions'.\n",
    "\n",
    "    Returns:\n",
    "    - A tuple containing:\n",
    "      - The total solutions rate: total number of solutions divided by the number of entries in the data.\n",
    "      - The coverage rate: the number of entries with positive reactions divided by the number of entries in the data.\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        return 0.0, 0.0\n",
    "\n",
    "    total_solutions = []\n",
    "    coverage = 0\n",
    "    fpr = []\n",
    "    for entry in data:\n",
    "        solutions = []\n",
    "        false_solutions = []\n",
    "        if solutions_column in entry and isinstance(entry[solutions_column], list):\n",
    "            #total_solutions += len(entry[solutions_column])\n",
    "            solutions = false_solutions = len(entry[solutions_column])\n",
    "            total_solutions.append(solutions)\n",
    "        else:\n",
    "            raise KeyError(f\"Missing or invalid '{solutions_column}' in entry: {entry}\")\n",
    "\n",
    "        if positive_columns in entry and entry[positive_columns]:\n",
    "            false_solutions -= 1\n",
    "            coverage += 1\n",
    "        if solutions > 0:\n",
    "            fpr.append(round(false_solutions/solutions, 2))\n",
    "        else:\n",
    "            fpr.append(1)\n",
    "\n",
    "    total_entries = len(data)\n",
    "\n",
    "    total_solutions_mean = round(np.mean(total_solutions), 2)\n",
    "    #total_solutions_std = round(np.std(total_solutions),2)\n",
    "    coverage_rate = coverage / total_entries\n",
    "\n",
    "    return total_solutions_mean, round(coverage_rate*100,2), round(np.mean(fpr),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data_fw = [[nh_r0_fw, nh_r1_fw, nh_r2_fw, nh_r3_fw], \n",
    "                [h_r0_fw, h_r1_fw, h_r2_fw, h_r3_fw],\n",
    "                [gh_r0_fw, gh_r1_fw, gh_r2_fw, gh_r3_fw],\n",
    "                [hier_r0_fw, hier_r1_fw, hier_r2_fw, hier_r3_fw]]\n",
    "\n",
    "data_list_dict_fw_cover = [{'Type':r'$Q_{\\text{raw}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}, \n",
    "                     {'Type':r'$Q_{\\text{complete}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}, \n",
    "                     {'Type':r'$Q_{\\text{cyclic}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}, \n",
    "                    {'Type':r'$Q_{\\text{hier}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}]\n",
    "\n",
    "data_list_dict_fw_sol = [{'Type':r'$Q_{\\text{raw}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}, \n",
    "                     {'Type':r'$Q_{\\text{complete}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}, \n",
    "                     {'Type':r'$Q_{\\text{cyclic}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}, \n",
    "                    {'Type':r'$Q_{\\text{hier}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}]\n",
    "\n",
    "data_list_dict_fw_fpr = [{'Type':r'$Q_{\\text{raw}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}, \n",
    "                     {'Type':r'$Q_{\\text{complete}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}, \n",
    "                     {'Type':r'$Q_{\\text{cyclic}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}, \n",
    "                    {'Type':r'$Q_{\\text{hier}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}]\n",
    "\n",
    "\n",
    "list_data_bw = [[nh_r0_bw, nh_r1_bw, nh_r2_bw, nh_r3_bw], \n",
    "                [h_r0_bw, h_r1_bw, h_r2_bw, h_r3_bw],\n",
    "                [gh_r0_bw, gh_r1_bw, gh_r2_bw, gh_r3_bw],\n",
    "                [hier_r0_bw, hier_r1_bw, hier_r2_bw, hier_r3_bw]]\n",
    "\n",
    "data_list_dict_bw_cover = [{'Type':r'$Q_{\\text{raw}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}, \n",
    "                     {'Type':r'$Q_{\\text{complete}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}, \n",
    "                     {'Type':r'$Q_{\\text{cyclic}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}, \n",
    "                    {'Type':r'$Q_{\\text{hier}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}]\n",
    "\n",
    "data_list_dict_bw_sol = [{'Type':r'$Q_{\\text{raw}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}, \n",
    "                     {'Type':r'$Q_{\\text{complete}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}, \n",
    "                     {'Type':r'$Q_{\\text{cyclic}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}, \n",
    "                    {'Type':r'$Q_{\\text{hier}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}]\n",
    "\n",
    "data_list_dict_bw_fpr = [{'Type':r'$Q_{\\text{raw}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}, \n",
    "                     {'Type':r'$Q_{\\text{complete}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}, \n",
    "                     {'Type':r'$Q_{\\text{cyclic}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}, \n",
    "                    {'Type':r'$Q_{\\text{hier}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, data in enumerate(list_data_fw):\n",
    "    for radius, value in enumerate(data):\n",
    "        result = reconstruction_rate_solutions(value)\n",
    "        data_list_dict_fw_cover[key][f'R{radius}'] = result[1]\n",
    "        data_list_dict_fw_sol[key][f'R{radius}'] = result[0]\n",
    "        data_list_dict_fw_fpr[key][f'R{radius}'] = result[2]\n",
    "\n",
    "for key, data in enumerate(list_data_bw):\n",
    "    for radius, value in enumerate(data):\n",
    "        result = reconstruction_rate_solutions(value)\n",
    "        data_list_dict_bw_cover[key][f'R{radius}'] = result[1]\n",
    "        data_list_dict_bw_sol[key][f'R{radius}'] = result[0]\n",
    "        data_list_dict_bw_fpr[key][f'R{radius}'] = result[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw_list_dict = []\n",
    "for i in range(len(data_list_dict_fw_sol)):\n",
    "    new_dict = {'Type':[], 'reconstruction_rates': [], 'number_of_solutions':[]}\n",
    "    new_dict['Type'] = data_list_dict_fw_sol[i]['Type']\n",
    "    new_dict['reconstruction_rates'].extend([data_list_dict_fw_cover[i][f'R{j}'] for j in range(4)])\n",
    "    new_dict['number_of_solutions'].extend([data_list_dict_fw_fpr[i][f'R{j}'] for j in range(4)])\n",
    "    fw_list_dict.append(new_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_list_dict = []\n",
    "for i in range(len(data_list_dict_bw_sol)):\n",
    "    new_dict = {'Type':[], 'reconstruction_rates': [], 'number_of_solutions':[]}\n",
    "    new_dict['Type'] = data_list_dict_bw_sol[i]['Type']\n",
    "    new_dict['reconstruction_rates'].extend([data_list_dict_bw_cover[i][f'R{j}'] for j in range(4)])\n",
    "    new_dict['number_of_solutions'].extend([data_list_dict_bw_fpr[i][f'R{j}'] for j in range(4)])\n",
    "    bw_list_dict.append(new_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw_list_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_list_dict[-2:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw_list_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data(data):\n",
    "    # Initialize a dictionary to store the extracted data\n",
    "    structured_data = {\n",
    "        \"Type\": [],\n",
    "        \"Reconstruction Rate R0\": [],\n",
    "        \"Reconstruction Rate R1\": [],\n",
    "        \"Reconstruction Rate R2\": [],\n",
    "        \"Reconstruction Rate R3\": [],\n",
    "        \"Number of Solutions R0\": [],\n",
    "        \"Number of Solutions R1\": [],\n",
    "        \"Number of Solutions R2\": [],\n",
    "        \"Number of Solutions R3\": []\n",
    "    }\n",
    "\n",
    "    # Iterate through each item in the input data\n",
    "    for item in data:\n",
    "        # Append the type\n",
    "        structured_data[\"Type\"].append(item[\"Type\"])\n",
    "        \n",
    "        # Append reconstruction rates for R0, R1, and R2\n",
    "        structured_data[\"Reconstruction Rate R0\"].append(item[\"reconstruction_rates\"][0])\n",
    "        structured_data[\"Reconstruction Rate R1\"].append(item[\"reconstruction_rates\"][1])\n",
    "        structured_data[\"Reconstruction Rate R2\"].append(item[\"reconstruction_rates\"][2])\n",
    "        structured_data[\"Reconstruction Rate R3\"].append(item[\"reconstruction_rates\"][3])\n",
    "        \n",
    "        # Append number of solutions for R0, R1, and R2\n",
    "        structured_data[\"Number of Solutions R0\"].append(item[\"number_of_solutions\"][0])\n",
    "        structured_data[\"Number of Solutions R1\"].append(item[\"number_of_solutions\"][1])\n",
    "        structured_data[\"Number of Solutions R2\"].append(item[\"number_of_solutions\"][2])\n",
    "        structured_data[\"Number of Solutions R3\"].append(item[\"number_of_solutions\"][3])\n",
    "\n",
    "    return structured_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_fw =  pd.DataFrame(convert_data(fw_list_dict))\n",
    "df_combined_bw =  pd.DataFrame(convert_data(bw_list_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Enable LaTeX rendering in matplotlib\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('text.latex', preamble=r'\\usepackage{amsmath}')  # Ensure amsmath is loaded\n",
    "\n",
    "def plot_reconstruction_rate(df, ax, colors, title='A'):\n",
    "    width = 0.2  # Adjusted width of the bars to fit four bars\n",
    "    x = range(len(df[\"Type\"]))\n",
    "\n",
    "    # Plotting Reconstruction Rates with adjusted bar positions for clarity\n",
    "    bars_r0 = ax.bar([pos - 1.5*width for pos in x], round(df[\"Reconstruction Rate R0\"],0), width=width, label='R0', color=colors[0])\n",
    "    bars_r1 = ax.bar([pos - 0.5*width for pos in x], round(df[\"Reconstruction Rate R1\"],0), width=width, label='R1', color=colors[1])\n",
    "    bars_r2 = ax.bar([pos + 0.5*width for pos in x], round(df[\"Reconstruction Rate R2\"], 0), width=width, label='R2', color=colors[2])\n",
    "    bars_r3 = ax.bar([pos + 1.5*width for pos in x], round(df[\"Reconstruction Rate R3\"],0), width=width, label='R3', color=colors[3])\n",
    "\n",
    "    # Adding numbers above bars with bold formatting for better visibility\n",
    "    for bars in [bars_r0, bars_r1, bars_r2, bars_r3]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.annotate(f'{height:.0f}', \n",
    "                        xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                        xytext=(0, 3),  # 3 points vertical offset\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom', \n",
    "                        fontweight='medium', fontsize=20)\n",
    "\n",
    "    # Aesthetic enhancements\n",
    "    ax.set_ylabel(r'Reconstruction Rate (\\%)', fontsize=24, fontweight='medium')\n",
    "    ax.set_title(title, fontsize=30, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(df[\"Type\"], rotation=45, fontsize=24)\n",
    "    #ax.set_xticklabels([r'$Q_{\\text{raw}}$', r'$Q_{\\text{complete}}$', r'$Q_{\\text{cyclic}}$', r'$Q_{\\text{hier}}$'], rotation=45, fontsize=24)\n",
    "    ax.set_yticks([0,20,40,60,80])\n",
    "    ax.set_yticklabels([0,20,40,60,80], fontsize=20)\n",
    "    ax.grid(True, which='major', linestyle='--', linewidth='0.5', color='grey')\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "def plot_number_of_solutions(df, ax, colors, title='B'):\n",
    "    width = 0.2  # Adjusted width for four bars\n",
    "    x = range(len(df[\"Type\"]))\n",
    "\n",
    "    # Plotting Number of Solutions with consistent styling\n",
    "    bars_r0 = ax.bar([pos - 1.5*width for pos in x], round(100*df[\"Number of Solutions R0\"]), width=width, label='R0', color=colors[0])\n",
    "    bars_r1 = ax.bar([pos - 0.5*width for pos in x], round(100*df[\"Number of Solutions R1\"]), width=width, label='R1', color=colors[1])\n",
    "    bars_r2 = ax.bar([pos + 0.5*width for pos in x], round(100*df[\"Number of Solutions R2\"]), width=width, label='R2', color=colors[2])\n",
    "    bars_r3 = ax.bar([pos + 1.5*width for pos in x], round(100*df[\"Number of Solutions R3\"]), width=width, label='R3', color=colors[3])\n",
    "\n",
    "    # Adding numbers above bars with bold formatting\n",
    "    for bars in [bars_r0, bars_r1, bars_r2, bars_r3]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.annotate(f'{height:.0f}', \n",
    "                        xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                        xytext=(0, 3),  # 3 points vertical offset\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom', \n",
    "                        fontweight='medium', fontsize=20)\n",
    "\n",
    "    # Aesthetic enhancements\n",
    "    ax.set_ylabel(r'False Possitive Rate (\\%)', fontsize=24, fontweight='medium')\n",
    "    ax.set_title(title, fontsize=30, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(df[\"Type\"], rotation=45, fontsize=24)\n",
    "    #ax.set_xticklabels([r'$Q_{\\text{raw}}$', r'$Q_{\\text{complete}}$', r'$Q_{\\text{cyclic}}$', r'$Q_{\\text{hier}}$'], rotation=45, fontsize=24)\n",
    "    ax.set_yticks([0,20,40,60,80,100])\n",
    "    ax.set_yticklabels([0,20,40,60,80,100], fontsize=20)\n",
    "    ax.grid(True, which='major', linestyle='--', linewidth='0.5', color='grey')\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "# Define colors for R0, R1, R2\n",
    "colors = ['#3A8EBA', '#92C5DE', '#F4A582', '#D6604D']\n",
    "\n",
    "\n",
    "# Creating the figure and subplots\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20, 18))\n",
    "\n",
    "# Plotting data\n",
    "plot_reconstruction_rate(df_combined_fw, ax1, colors, 'A')\n",
    "plot_reconstruction_rate(df_combined_bw, ax2, colors, 'B')\n",
    "\n",
    "plot_number_of_solutions(df_combined_fw, ax3, colors, 'C')\n",
    "plot_number_of_solutions(df_combined_bw, ax4, colors, 'D')\n",
    "\n",
    "\n",
    "fig.legend(['R0', 'R1', 'R2', 'R3'], loc='lower center', ncol=2, fontsize=20, bbox_to_anchor=(0.5, 0.001))\n",
    "\n",
    "# Adjusting layout\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(bottom=0.1) \n",
    "fig.savefig('./fig/template_false_rate_compare.pdf', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. TopK accuracy random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "from SynTemp.SynRule.rule_benchmark import RuleBenchmark\n",
    "from SynTemp.SynChemistry.sf_random import SFRandom\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "def random_evaluation(data: List[Dict], ground_truth_key: str = 'reactions', rank_list_key: str = \"ranked_reactions\", k: int = 1, ignore_stereo: bool = True, n_eval: int = 10, n_jobs: int = 4) -> Tuple[float, float, List[float]]:\n",
    "    \"\"\"\n",
    "    Evaluate the performance of a ranking system using random seeds in parallel.\n",
    "\n",
    "    Parameters:\n",
    "    - data: List of dictionaries containing the data.\n",
    "    - ground_truth_key: The key for the ground truth reactions. Default is 'reactions'.\n",
    "    - rank_list_key: The key for the ranked reactions list. Default is 'ranked_reactions'.\n",
    "    - k: The top k rankings to consider for accuracy. Default is 1.\n",
    "    - ignore_stereo: Boolean flag to ignore stereo chemistry. Default is True.\n",
    "    - n_eval: Number of evaluations to perform. Default is 10.\n",
    "    - n_jobs: The number of jobs to run in parallel. Default is -1 (use all available processors).\n",
    "\n",
    "    Returns:\n",
    "    - A tuple containing:\n",
    "      - Mean accuracy of the evaluations.\n",
    "      - Standard deviation of the accuracies.\n",
    "      - List of individual evaluation results.\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        raise ValueError(\"Data list is empty.\")\n",
    "\n",
    "    def evaluate(seed: int) -> float:\n",
    "        try:\n",
    "            result = RuleBenchmark.TopKAccuracy(data, ground_truth_key, rank_list_key, k, ignore_stereo, scoring_function=SFRandom(seed))\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error during evaluation with seed {seed}: {e}\")\n",
    "        return result\n",
    "\n",
    "    seeds = [random.randint(0, 1000000) for _ in range(n_eval)]\n",
    "    results = Parallel(n_jobs=n_jobs)(delayed(evaluate)(seed) for seed in seeds)\n",
    "\n",
    "    mean_accuracy = round(np.mean(results),2)\n",
    "    std_accuracy = round(np.std(results),2)\n",
    "\n",
    "    return mean_accuracy, std_accuracy, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data_fw = [[nh_r0_fw, nh_r1_fw, nh_r2_fw, nh_r3_fw], \n",
    "                [h_r0_fw, h_r1_fw, h_r2_fw, h_r3_fw],\n",
    "                [gh_r0_fw, gh_r1_fw, gh_r2_fw, gh_r3_fw],\n",
    "                [hier_r0_fw, hier_r1_fw, hier_r2_fw, hier_r3_fw]]\n",
    "data_list_dict_fw = [{'Type':r'$Q_{\\text{raw}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}, \n",
    "                     {'Type':r'$Q_{\\text{complete}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}, \n",
    "                     {'Type':r'$Q_{\\text{cyclic}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}, \n",
    "                    {'Type':r'$Q_{\\text{hier}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}]\n",
    "all_matrix_fw = []\n",
    "for key, data in enumerate(list_data_fw):\n",
    "    for radius, value in enumerate(data):\n",
    "        result = random_evaluation(value, k = 10)\n",
    "        data_list_dict_fw[key][f'R{radius}'] = f'{result[0]} ± {result[1]}'\n",
    "        all_matrix_fw.append(result[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data_bw = [[nh_r0_bw, nh_r1_bw, nh_r2_bw, nh_r3_bw], \n",
    "                [h_r0_bw, h_r1_bw, h_r2_bw, h_r3_bw],\n",
    "                [gh_r0_bw, gh_r1_bw, gh_r2_bw, gh_r3_bw],\n",
    "                [hier_r0_bw, hier_r1_bw, hier_r2_bw, hier_r3_bw]]\n",
    "\n",
    "data_list_dict_bw = [{'Type':r'$Q_{\\text{raw}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}, \n",
    "                     {'Type':r'$Q_{\\text{complete}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}, \n",
    "                     {'Type':r'$Q_{\\text{cyclic}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}, \n",
    "                    {'Type':r'$Q_{\\text{hier}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}]\n",
    "all_matrix_bw = []\n",
    "for key, data in enumerate(list_data_bw):\n",
    "    for radius, value in enumerate(data):\n",
    "        result = random_evaluation(value, k = 10)\n",
    "        data_list_dict_bw[key][f'R{radius}'] = f'{result[0]} ± {result[1]}'\n",
    "        all_matrix_bw.append(result[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "from typing import List\n",
    "\n",
    "def statistical_comparison(data_lists: List[List[float]]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Perform statistical comparison among multiple lists with Bonferroni correction\n",
    "    and return a matrix of corrected p-values.\n",
    "\n",
    "    Parameters:\n",
    "    - data_lists: A list of lists, where each sublist contains numerical data.\n",
    "\n",
    "    Returns:\n",
    "    - A matrix of corrected p-values representing pairwise comparisons.\n",
    "    \"\"\"\n",
    "    num_lists = len(data_lists)\n",
    "    p_value_matrix = np.zeros((num_lists, num_lists))\n",
    "    num_comparisons = num_lists * (num_lists - 1) // 2  # Total number of comparisons\n",
    "\n",
    "    for i in range(num_lists):\n",
    "        for j in range(i, num_lists):\n",
    "            if i == j:\n",
    "                p_value_matrix[i, j] = np.nan\n",
    "            else:\n",
    "                _, p_value = ttest_ind(data_lists[i], data_lists[j], equal_var=False)\n",
    "                corrected_p_value = np.round(p_value * num_comparisons, 3)\n",
    "                # Ensure that corrected p-values do not exceed 1\n",
    "                corrected_p_value = min(corrected_p_value, 1.0)\n",
    "                p_value_matrix[i, j] = corrected_p_value\n",
    "                p_value_matrix[j, i] = corrected_p_value\n",
    "\n",
    "    return p_value_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw_test = statistical_comparison(all_matrix_fw)\n",
    "bw_test = statistical_comparison(all_matrix_bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = [r'$Q_{\\text{raw}}-R_0$', r'$Q_{\\text{raw}}-R_1$', r'$Q_{\\text{raw}}-R_2$',r'$Q_{\\text{raw}}-R_3$',\n",
    "        r'$Q_{\\text{complete}}-R_0$', r'$Q_{\\text{complete}}-R_1$', r'$Q_{\\text{complete}}-R_2$',r'$Q_{\\text{complete}}-R_3$',\n",
    "        r'$Q_{\\text{cyclic}}-R_0$', r'$Q_{\\text{cyclic}}-R_1$', r'$Q_{\\text{cyclic}}-R_2$',r'$Q_{\\text{cyclic}}-R_3$',\n",
    "        r'$Q_{\\text{hier}}-R_0$', r'$Q_{\\text{hier}}-R_1$', r'$Q_{\\text{hier}}-R_2$',r'$Q_{\\text{hier}}-R_3$',\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "def plot_p_value_heatmap(p_value_matrix: np.ndarray, names: list):\n",
    "    \"\"\"\n",
    "    Plot a heatmap for the p-value matrix with two distinct colors indicating p-values\n",
    "    greater than 0.05 and less than or equal to 0.05, without a color bar but with an external legend\n",
    "    including a legend for 'N/A' values.\n",
    "\n",
    "    Parameters:\n",
    "    - p_value_matrix: A matrix of p-values representing pairwise comparisons.\n",
    "    - names: List of names corresponding to the matrix indices.\n",
    "    \"\"\"\n",
    "    # Mask diagonal for N/A values\n",
    "    np.fill_diagonal(p_value_matrix, -1)\n",
    "\n",
    "    # Enhanced color palette for better contrast\n",
    "    colors = [\"#D3D3D3\", \"#A2CEE3\", \"#D6604D\"]  # Blue for p <= 0.05, Red for p > 0.05, Gray for N/A\n",
    "    cmap = ListedColormap(colors)\n",
    "    boundaries = [-1, 0, 0.05, 1]  # Define boundaries for significance and N/A values\n",
    "    norm = BoundaryNorm(boundaries, cmap.N, clip=True)\n",
    "\n",
    "    # Create the figure\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    ax = sns.heatmap(p_value_matrix, annot=False, fmt=\".2f\", cmap=cmap, norm=norm,\n",
    "                     xticklabels=names, yticklabels=names,\n",
    "                     cbar=False,  \n",
    "                     linewidths=.5, linecolor='black')\n",
    "\n",
    "   \n",
    "    plt.xticks(rotation=45, fontsize = 14)\n",
    "    \n",
    "    plt.yticks(rotation=0, fontsize = 14)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    \n",
    "    legend_elements = [\n",
    "        plt.Line2D([0], [0], marker='o', color='w', label=r'$p \\leq 0.05$', markersize=10, markerfacecolor='#A2CEE3'),\n",
    "        plt.Line2D([0], [0], marker='o', color='w', label=r'$p > 0.05$', markersize=10, markerfacecolor='#FA8072'),\n",
    "        plt.Line2D([0], [0], marker='o', color='w', label='N/A', markersize=10, markerfacecolor='#D3D3D3')\n",
    "    ]\n",
    "    # Position the legend outside of the heatmap\n",
    "    ax.legend(handles=legend_elements, bbox_to_anchor=(1.02, 1), loc='upper left', prop={\"size\":16})\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "def plot_p_value_heatmap(p_value_matrix: np.ndarray, names: list, ax=None, title='A'):\n",
    "    \"\"\"\n",
    "    Plot a heatmap for the p-value matrix with two distinct colors indicating p-values\n",
    "    greater than 0.05 and less than or equal to 0.05, without a color bar but with an external legend\n",
    "    including a legend for 'N/A' values.\n",
    "\n",
    "    Parameters:\n",
    "    - p_value_matrix: A matrix of p-values representing pairwise comparisons.\n",
    "    - names: List of names corresponding to the matrix indices.\n",
    "    - ax: Optional matplotlib axes object. If none is provided, one will be created.\n",
    "    \"\"\"\n",
    "    # Mask diagonal for N/A values\n",
    "    np.fill_diagonal(p_value_matrix, -1)\n",
    "\n",
    "    # Enhanced color palette for better contrast\n",
    "    colors = [\"#D3D3D3\", \"#A2CEE3\", \"#D6604D\"]  # Blue for p <= 0.05, Red for p > 0.05, Gray for N/A\n",
    "    cmap = ListedColormap(colors)\n",
    "    boundaries = [-1, 0, 0.05, 1]  # Define boundaries for significance and N/A values\n",
    "    norm = BoundaryNorm(boundaries, cmap.N, clip=True)\n",
    "\n",
    "    # Check if an axes object is provided; if not, create a new figure and axes\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    sns.heatmap(p_value_matrix, annot=False, fmt=\".2f\", cmap=cmap, norm=norm,\n",
    "                xticklabels=names, yticklabels=names,\n",
    "                cbar=False, ax=ax,\n",
    "                linewidths=.5, linecolor='black')\n",
    "    ax.set_title(title, fontsize = 30, weight = 'bold')\n",
    "    ax.set_xticklabels(names, rotation=45, fontsize=20)\n",
    "    ax.set_yticklabels(names, rotation=0, fontsize=20)\n",
    "    ax.figure.tight_layout()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming plot_p_value_heatmap is defined elsewhere with the correct definition to accept 'ax'\n",
    "# Set style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create figure and subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10), dpi=120)\n",
    "fig.subplots_adjust(wspace=0.3)\n",
    "\n",
    "# Assuming 'names' variable is defined correctly and passed as 'names'\n",
    "plot_p_value_heatmap(fw_test, name, axes[0], 'A. Forward prediction')\n",
    "plot_p_value_heatmap(bw_test, name, axes[1], 'B. Backward prediction')\n",
    "\n",
    "legend_elements = [\n",
    "    plt.Line2D([0], [0], marker='o', color='w', label=r'$p \\leq 0.05$', markersize=10, markerfacecolor='#A2CEE3'),\n",
    "    plt.Line2D([0], [0], marker='o', color='w', label=r'$p > 0.05$', markersize=10, markerfacecolor='#D6604D'),\n",
    "    plt.Line2D([0], [0], marker='o', color='w', label='N/A', markersize=10, markerfacecolor='#D3D3D3')\n",
    "]\n",
    "\n",
    "# Position the legend on the figure level, outside the rightmost plot\n",
    "fig.legend(handles=legend_elements, bbox_to_anchor=(0.5, 0.01), ncols=3, loc='lower center', fontsize=16)\n",
    "\n",
    "# fig.legend(['R0', 'R1', 'R2', 'R3'], loc='lower center', ncol=2, fontsize=20, bbox_to_anchor=(0.5, 0.001))\n",
    "fig.subplots_adjust(bottom=0.16) \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data_list_dict_fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_bar_compare(data, ax, title=\"Values by Type and R Condition\", show_values=True):\n",
    "    \"\"\"\n",
    "    Plot a heatmap for the p-value matrix on the provided axes object.\n",
    "\n",
    "    Parameters:\n",
    "    - data: List of dictionaries with types and values for R0, R1, R2, R3.\n",
    "    - ax: Matplotlib axes object to plot the heatmap.\n",
    "    - title: Optional title for the plot.\n",
    "    - show_values: Boolean to indicate whether to display the values on the bars.\n",
    "    \"\"\"\n",
    "    types = [item['Type'] for item in data]\n",
    "    R_labels = ['R0', 'R1', 'R2', 'R3']\n",
    "    colors = ['#3A8EBA', '#92C5DE', '#F4A582', '#D6604D']\n",
    "    means = {r: [] for r in R_labels}\n",
    "    std_devs = {r: [] for r in R_labels}\n",
    "\n",
    "    # Parse the data to extract means and standard deviations\n",
    "    for item in data:\n",
    "        for r in R_labels:\n",
    "            value, error = item[r].split(' ± ')\n",
    "            means[r].append(float(value))\n",
    "            std_devs[r].append(float(error))\n",
    "    \n",
    "    # Number of groups and bar width\n",
    "    n_groups = len(data)\n",
    "    index = np.arange(n_groups)\n",
    "    bar_width = 0.2\n",
    "\n",
    "    # Creating bars for each R\n",
    "    for i, r in enumerate(R_labels):\n",
    "        bars = ax.bar(index + i * bar_width, means[r], bar_width, yerr=std_devs[r], \n",
    "                      color=colors[i], label=r)\n",
    "\n",
    "        # Optionally add values on top of the bars\n",
    "        if show_values:\n",
    "            for bar in bars:\n",
    "                height = bar.get_height()\n",
    "                ax.annotate(f'{height:.1f}',\n",
    "                            xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                            xytext=(0, 3),  # 3 points vertical offset\n",
    "                            textcoords=\"offset points\",\n",
    "                            ha='center', va='bottom', fontsize=18)\n",
    "\n",
    "    # Adding labels, title and custom x-axis tick labels, etc.\n",
    "    #ax.set_xlabel('Type', fontsize=16)\n",
    "    ax.set_ylabel(r'Average Accuracy (\\%)', fontsize=24)\n",
    "    ax.set_title(title, fontsize = 30, weight = 'bold')\n",
    "    ax.set_xticks(index + 1.5 * bar_width)\n",
    "    ax.set_xticklabels(types, rotation=45, fontsize=20)\n",
    "    ax.set_yticks([0,10,20,30,40])\n",
    "    ax.set_yticklabels([0,10,20,30,40], fontsize=20)\n",
    "    ax.legend(fontsize=20)\n",
    "    \n",
    "\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(16, 6), dpi=600)\n",
    "# fig.subplots_adjust(wspace=0.14)\n",
    "\n",
    "# plot_bar_compare(data_list_dict_fw, axes[0], 'A. Top 1 accuracy - Forward prediction')\n",
    "# plot_bar_compare(data_list_dict_bw, axes[1], 'B. Top 1 accuracy - Backward prediction')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the style for seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Assuming plot_p_value_heatmap is defined elsewhere and it accepts 'ax' as a parameter\n",
    "# Assuming 'fw_test', 'bw_test', 'data_list_dict_fw', 'data_list_dict_bw', and 'name' are defined elsewhere\n",
    "\n",
    "# Define legend elements\n",
    "legend_elements = [\n",
    "    plt.Line2D([0], [0], marker='o', color='w', label=r'$p \\leq 0.05$', markersize=10, markerfacecolor='#A2CEE3'),\n",
    "    plt.Line2D([0], [0], marker='o', color='w', label=r'$p > 0.05$', markersize=10, markerfacecolor='#D6604D'),\n",
    "    plt.Line2D([0], [0], marker='o', color='w', label='N/A', markersize=10, markerfacecolor='#D3D3D3')\n",
    "]\n",
    "\n",
    "# Create figure and subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 16), dpi=1200)\n",
    "fig.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "# Plot heatmaps on respective axes\n",
    "plot_bar_compare(data_list_dict_fw, axes[0, 0], 'A. Forward Prediction - Top 1 Accuracy')\n",
    "plot_bar_compare(data_list_dict_bw, axes[0, 1], 'B. Backward Prediction - Top 1 Accuracy')\n",
    "plot_p_value_heatmap(fw_test, name, axes[1, 0], 'C. Forward Prediction - T-test Results')\n",
    "plot_p_value_heatmap(bw_test, name, axes[1, 1], 'D. Backward Prediction - T-test Results')\n",
    "\n",
    "\n",
    "# Position the legend on the figure level, outside the rightmost plot\n",
    "fig.legend(handles=legend_elements, bbox_to_anchor=(0.5, 0.01), ncols=3, loc='lower center', fontsize=16, prop={'size':20})\n",
    "\n",
    "# Adjust the position of the overall figure to make room for the legend\n",
    "fig.subplots_adjust(bottom=0.12)\n",
    "fig.savefig('./fig/top_1_temp_compare.pdf', dpi=1200)\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Time processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hier = [3139.097, 3854.369, 5885.342, 6294.58]\n",
    "good = [2145.046, 14497.126, 137876.927, 307741.2]\n",
    "h = [3744.996, 22326.635, 169062.646, 361867.284]\n",
    "non_h = [4348.231, 23538.139, 171314.111, 364311.571]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Define the time format from the logs\n",
    "time_format = \"%Y-%m-%d %H:%M:%S,%f\"\n",
    "\n",
    "# Timestamps from the logs\n",
    "start_time_str = \"2024-06-14 15:56:44,503\"\n",
    "end_time_str = \"2024-06-18 21:08:36,074\"\n",
    "\n",
    "# Convert string to datetime\n",
    "start_time = datetime.strptime(start_time_str, time_format)\n",
    "end_time = datetime.strptime(end_time_str, time_format)\n",
    "\n",
    "# Calculate difference in seconds\n",
    "time_difference = end_time - start_time\n",
    "total_seconds = time_difference.total_seconds()\n",
    "\n",
    "print(\"Total time in seconds:\", total_seconds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Enable LaTeX rendering in matplotlib\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('text.latex', preamble=r'\\usepackage{amsmath}')  # Ensure amsmath is loaded\n",
    "\n",
    "\n",
    "def plot_processing_times(times):\n",
    "    # Convert to hours\n",
    "    for key in times:\n",
    "        times[key] = np.array(times[key]) / 3600\n",
    "\n",
    "    # Stages\n",
    "    stages = ['R0', 'R1', 'R2', 'R3']\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(times, index=stages).reset_index().melt(id_vars='index', var_name='Method', value_name='Time (hours)')\n",
    "    df.rename(columns={'index': 'Stage'}, inplace=True)\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    palette = sns.color_palette(\"coolwarm\", n_colors=len(times.keys()))\n",
    "    bar_plot = sns.barplot(x='Stage', y='Time (hours)', hue='Method', data=df, palette=palette)\n",
    "\n",
    "    plt.title('Processing Time across Different Methods by Radius', fontsize=16)\n",
    "    plt.xlabel(None)\n",
    "    plt.ylabel('Time (Hours)', fontsize=14)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    plt.legend(title='Rule Type', title_fontsize='16', fontsize='14', loc='upper left', bbox_to_anchor=(0.01, 1))\n",
    "\n",
    "    # Add text annotations on the bars\n",
    "    for p in bar_plot.patches:\n",
    "        bar_height = p.get_height()\n",
    "        if bar_height > 0.01:  # Adjust this threshold as needed\n",
    "            bar_plot.annotate(format(p.get_height(), '.1f'), \n",
    "                            (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                            ha = 'center', va = 'center', \n",
    "                            xytext = (0, 9), \n",
    "                            textcoords = 'offset points', fontsize=14)\n",
    "\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)  # Optional: add grid for better readability\n",
    "    plt.tight_layout()  # Adjust layout to make room for the legend\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Enable LaTeX rendering in matplotlib\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('text.latex', preamble=r'\\usepackage{amsmath}')  # Ensure amsmath is loaded\n",
    "\n",
    "\n",
    "def plot_processing_times(times, ax=None):\n",
    "    # Convert to hours\n",
    "    for key in times:\n",
    "        times[key] = np.array(times[key]) / 3600\n",
    "\n",
    "    # Stages\n",
    "    stages = [r'$R_{0}$', r'$R_{1}$', r'$R_{2}$', r'$R_{3}$']\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(times, index=stages).reset_index().melt(id_vars='index', var_name='Method', value_name='Time (hours)')\n",
    "    df.rename(columns={'index': 'Stage'}, inplace=True)\n",
    "\n",
    "    # Create the plot on the provided ax\n",
    "    if ax is None:\n",
    "        ax = plt.gca()  # Get current axis if not provided\n",
    "\n",
    "    palette = sns.color_palette(\"coolwarm\", n_colors=len(times.keys()))\n",
    "    bar_plot = sns.barplot(x='Stage', y='Time (hours)', hue='Method', data=df, palette=palette, ax=ax)\n",
    "\n",
    "    ax.set_title('A. Processing Time across Different Methods by Radius', fontsize=20, weight = 'bold')\n",
    "    ax.set_xlabel(None)\n",
    "    ax.set_ylabel('Time (Hours)', fontsize=18)\n",
    "    ax.set_xticks(ax.get_xticks())\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), fontsize=18)\n",
    "    ax.set_yticks(ax.get_yticks())\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=18)\n",
    "    ax.legend(title='Rule Type', title_fontsize='20', fontsize='18', loc='upper left', bbox_to_anchor=(0.01, 1))\n",
    "\n",
    "    # Add text annotations on the bars\n",
    "    for p in bar_plot.patches:\n",
    "        bar_height = p.get_height()\n",
    "        if bar_height > 0.01:  # Adjust this threshold as needed\n",
    "            if p.get_height() < 100:\n",
    "                bar_plot.annotate(format(p.get_height(), '.1f'), \n",
    "                                (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                                ha='center', va='center', \n",
    "                                xytext=(0, 9), \n",
    "                                textcoords='offset points', fontsize=16)\n",
    "            else:\n",
    "                if p.get_height() < 101:\n",
    "                    #p.get_height() = 100\n",
    "                    bar_plot.annotate(format(100, '.0f'), \n",
    "                                    (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                                    ha='center', va='center', \n",
    "                                    xytext=(0, 9), \n",
    "                                    textcoords='offset points', fontsize=16)\n",
    "                else:\n",
    "                    bar_plot.annotate(format(p.get_height(), '.0f'), \n",
    "                                (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                                ha='center', va='center', \n",
    "                                xytext=(0, 9), \n",
    "                                textcoords='offset points', fontsize=16)\n",
    "\n",
    "    ax.grid(True, linestyle='--', alpha=0.6)  # Optional: add grid for better readability\n",
    "    #plt.tight_layout()  # Adjust layout to make room for the legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "def plot_combined_roc(forward_data_list, backward_data_list, ax):\n",
    "    # Set the Seaborn style\n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    # Colors and markers for better distinction\n",
    "    forward_color = '#3A8EBA'\n",
    "    backward_color = '#D6604D'\n",
    "    markers = ['o', '^', 's', 'p']  # Different marker for each R value\n",
    "    marker_labels = [r'$R_{0}$', r'$R_{1}$', r'$R_{2}$', r'$R_{3}$']\n",
    "\n",
    "    # Function to plot ROC curves for a given data list and axis\n",
    "    def plot_roc(data_list, ax, direction, color):\n",
    "        for data in data_list:\n",
    "            template_type = data['Type']\n",
    "            reconstruction_rates = data['reconstruction_rates']\n",
    "            number_of_solutions = data['number_of_solutions']\n",
    "            \n",
    "            # Normalize the reconstruction rates (converting to proportions)\n",
    "            TPR = [x / 100 for x in reconstruction_rates]  # True Positive Rate\n",
    "\n",
    "            # Applying Min-Max scaling to number_of_solutions to calculate FPR\n",
    "            min_solution = min(number_of_solutions)\n",
    "            max_solution = max(number_of_solutions)\n",
    "            FPR = [(x - min_solution) / (max_solution - min_solution) for x in number_of_solutions]  # False Positive Rate\n",
    "            \n",
    "            # Calculate the AUC\n",
    "            roc_auc = auc(FPR, TPR)\n",
    "            \n",
    "            # Plot ROC curve for the current template type\n",
    "            ax.plot(FPR, TPR, linestyle='-', color=color,\n",
    "                    label=f'{template_type} ({direction}) (AUC = {roc_auc:.2f})')\n",
    "            \n",
    "            # Plot each point with a different marker\n",
    "            for i, (fpr, tpr) in enumerate(zip(FPR, TPR)):\n",
    "                ax.plot(fpr, tpr, marker=markers[i], color=color)\n",
    "            # # Add data point markers and labels\n",
    "            # for i, (fpr, tpr) in enumerate(zip(FPR, TPR)):\n",
    "            #     ax.plot(fpr, tpr, marker=markers[i % len(markers)], color=color)\n",
    "            #     ax.annotate(fr'$R_{i}$', (fpr, tpr), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "\n",
    "    # Plot forward predictions\n",
    "    plot_roc(forward_data_list, ax, 'Forward', forward_color)\n",
    "    \n",
    "    # Plot backward predictions\n",
    "    plot_roc(backward_data_list, ax, 'Backward', backward_color)\n",
    "    \n",
    "    # Create a legend for the markers\n",
    "    for i, marker_label in enumerate(marker_labels):\n",
    "        ax.plot([], [], marker=markers[i], color='gray', label=marker_label, linestyle='None')\n",
    "\n",
    "    # Enhance the plot aesthetics\n",
    "    ax.set_xlabel('FPR', fontsize=18)\n",
    "    ax.set_ylabel(r'Reconstruction  rate $\\mathcal(R)$', fontsize=18)\n",
    "    ax.set_xticks(ax.get_xticks())\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), fontsize=18)\n",
    "    ax.set_yticks(ax.get_yticks())\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=18)\n",
    "    ax.legend(loc='lower right', ncol=3, fontsize=16, title_fontsize='18')\n",
    "    ax.set_title('B. Foward and Backward Performance by Radius', fontsize=20, weight = 'bold')\n",
    "    #sns.despine(ax=ax)\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_compare = {\n",
    "        r'$Q_{\\text{hier}}$': [3139.097, 3854.369, 5885.342, 6294.58],\n",
    "        r'$Q_{\\text{cyclic}}$': [2145.046, 14497.126, 137876.927, 307741.2],\n",
    "        r'$Q_{\\text{complete}}$': [3744.996, 22326.635, 169062.646, 361867.284], \n",
    "        r'$Q_{\\text{raw}}$': [4348.231, 23538.139, 171314.111, 364311.571]\n",
    "    }\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(16, 8))\n",
    "plot_processing_times(times_compare, ax=axs[0])\n",
    "# Plot on the first subplot\n",
    "plot_combined_roc(fw_list_dict[-1:], bw_list_dict[-1:], ax=axs[1])\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace=0.18)\n",
    "plt.savefig('./fig/time_roc.pdf', dpi = 600)\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw_list_dict[-1:], bw_list_dict[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def find_optimal_cutoff(data):\n",
    "    optimal_cutoffs = []\n",
    "\n",
    "    for direction in data:\n",
    "        gmeans = []\n",
    "        best_index = 0\n",
    "        best_gmean = 0\n",
    "        \n",
    "        for i in range(len(direction['reconstruction_rates'])):\n",
    "            reconstruction_rate = direction['reconstruction_rates'][i]/100\n",
    "            fpr = direction['number_of_solutions'][i]\n",
    "            \n",
    "            # Compute Gmean\n",
    "            gmean = np.sqrt(reconstruction_rate * (1 - fpr))\n",
    "            gmeans.append(gmean)\n",
    "            \n",
    "            if gmean > best_gmean:\n",
    "                best_gmean = gmean\n",
    "                best_index = i\n",
    "        \n",
    "        optimal_cutoffs.append({\n",
    "            'Type': direction['Type'],\n",
    "            'optimal_cutoff': best_index,\n",
    "            'reconstruction_rate': direction['reconstruction_rates'][best_index],\n",
    "            'fpr': direction['number_of_solutions'][best_index],\n",
    "            'gmean': best_gmean,\n",
    "            'gmeans': gmeans\n",
    "        })\n",
    "\n",
    "    return optimal_cutoffs\n",
    "\n",
    "# Example data\n",
    "forward_data = [{'Type': '$Q_{\\\\text{hier}}$', 'reconstruction_rates': [78.93, 78.19, 74.67, 66.21], 'number_of_solutions': [0.94, 0.79, 0.61, 0.59]}]\n",
    "backward_data = [{'Type': '$Q_{\\\\text{hier}}$', 'reconstruction_rates': [78.93, 78.21, 74.77, 66.35], 'number_of_solutions': [0.94, 0.79, 0.73, 0.7]}]\n",
    "\n",
    "# Finding optimal cutoffs\n",
    "forward_optimal_cutoff = find_optimal_cutoff(forward_data)\n",
    "backward_optimal_cutoff = find_optimal_cutoff(backward_data)\n",
    "\n",
    "print(\"Forward Optimal Cutoff:\", forward_optimal_cutoff)\n",
    "print(\"Backward Optimal Cutoff:\", backward_optimal_cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_data_new = [{'Type': '$Q_{\\\\text{hier}}$', 'reconstruction_rates': [78.93, 78.19, 74.67, 66.21], 'number_of_solutions': [0.94, 0.79, 0.61, 0.59], 'gmeans': [2.176189329998657, 4.052147578753765, 5.396415476962463, 5.210191935044236]}]\n",
    "backward_data_new = [{'Type': '$Q_{\\\\text{hier}}$', 'reconstruction_rates': [78.93, 78.21, 74.77, 66.35], 'number_of_solutions': [0.94, 0.79, 0.73, 0.7], 'gmeans': [2.176189329998657, 4.05266578932929, 4.493094701873086, 4.461501989240843]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "from SynTemp.SynRule.rule_benchmark import RuleBenchmark\n",
    "from SynTemp.SynChemistry.sf_similarity import SFSimilarity\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "def _evaluation(data: List[Dict], ground_truth_key: str = 'reactions', rank_list_key: str = \"ranked_reactions\", ignore_stereo: bool = True, n_jobs: int = 4) -> Tuple[float, float, List[float]]:\n",
    "    \"\"\"\n",
    "    Evaluate the performance of a ranking system using random seeds in parallel.\n",
    "\n",
    "    Parameters:\n",
    "    - data: List of dictionaries containing the data.\n",
    "    - ground_truth_key: The key for the ground truth reactions. Default is 'reactions'.\n",
    "    - rank_list_key: The key for the ranked reactions list. Default is 'ranked_reactions'.\n",
    "    - ignore_stereo: Boolean flag to ignore stereo chemistry. Default is True.\n",
    "    - n_jobs: The number of jobs to run in parallel. Default is 4.\n",
    "\n",
    "    Returns:\n",
    "    - A tuple containing:\n",
    "      - Mean accuracy of the evaluations.\n",
    "      - Standard deviation of the accuracies.\n",
    "      - List of individual evaluation results.\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        raise ValueError(\"Data list is empty.\")\n",
    "    \n",
    "    # Define the function to compute TopKAccuracy\n",
    "    def compute_topk_accuracy(k):\n",
    "        return RuleBenchmark.TopKAccuracy(data, ground_truth_key, rank_list_key, k, ignore_stereo, scoring_function=SFSimilarity(['ECFP6']))\n",
    "\n",
    "    # Define the list of k values\n",
    "    k_values = [1, 3, 5, 10]\n",
    "\n",
    "    # Use joblib to parallelize the computation\n",
    "    results = Parallel(n_jobs=n_jobs, verbose=2)(delayed(compute_topk_accuracy)(k) for k in k_values)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data_fw = [[nh_r0_fw, nh_r1_fw, nh_r2_fw, nh_r3_fw], \n",
    "                [h_r0_fw, h_r1_fw, h_r2_fw, h_r3_fw],\n",
    "                [gh_r0_fw, gh_r1_fw, gh_r2_fw, gh_r3_fw],\n",
    "                [hier_r0_fw, hier_r1_fw, hier_r2_fw, hier_r3_fw]]\n",
    "data_list_dict_fw = [{'Type':r'$Q_{\\text{raw}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}, \n",
    "                     {'Type':r'$Q_{\\text{complete}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}, \n",
    "                     {'Type':r'$Q_{\\text{cyclic}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}, \n",
    "                    {'Type':r'$Q_{\\text{hier}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}]\n",
    "\n",
    "data_list_dict_bw = [{'Type':r'$Q_{\\text{raw}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}, \n",
    "                     {'Type':r'$Q_{\\text{complete}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}, \n",
    "                     {'Type':r'$Q_{\\text{cyclic}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}, \n",
    "                    {'Type':r'$Q_{\\text{hier}}$', \"R0\":[], \"R1\":[], \"R2\":[], \"R3\":[]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, data in enumerate(list_data_fw):\n",
    "    for radius, value in enumerate(data):\n",
    "        result = _evaluation(value)\n",
    "        data_list_dict_fw[key][f'R{radius}'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list_dict_fw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, data in enumerate(list_data_bw):\n",
    "    for radius, value in enumerate(data):\n",
    "        result = _evaluation(value)\n",
    "        data_list_dict_bw[key][f'R{radius}'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list_dict_bw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SynITSG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
