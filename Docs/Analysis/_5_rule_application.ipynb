{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Extract results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from _analysis._rule_app_analysis import automatic_results, save_results_to_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"../../Data/Temp/Benchmark/\"\n",
    "test_types = [\"Valid\", \"Test\"]\n",
    "temp_types = [\"Raw\", \"Complete\", \"Expand\"]\n",
    "predict_types = [\"fw\", \"bw\"]\n",
    "radius = [0, 1, 2, 3]\n",
    "results = automatic_results(test_types, temp_types, predict_types, radius, base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Barplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from _analysis._rule_app_analysis import load_results_from_json\n",
    "\n",
    "results = load_results_from_json(\"../../Data/Temp/Benchmark/raw_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "valid = results[\"Valid\"]\n",
    "valid_fw = valid[\"fw\"]\n",
    "valid_bw = valid[\"bw\"]\n",
    "fw = pd.DataFrame(valid_fw).T\n",
    "bw = pd.DataFrame(valid_bw).T\n",
    "fw.rename(\n",
    "    columns={\n",
    "        0: \"average_solution\",\n",
    "        # 1: r'\\mathcal(C)',\n",
    "        1: \"C\",\n",
    "        2: \"FPR\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "bw.rename(\n",
    "    columns={\n",
    "        0: \"average_solution\",\n",
    "        # 1: r'\\mathcal(C)',\n",
    "        1: \"C\",\n",
    "        2: \"FPR\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _analysis._rule_app_analysis import plot_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Creating the figure and subplots\n",
    "plt.rc(\"text\", usetex=True)\n",
    "plt.rc(\"text.latex\", preamble=r\"\\usepackage{amsmath}\")  # Ensure amsmath is loaded\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20, 18))\n",
    "fontsettings = {\n",
    "    \"title_size\": 32,\n",
    "    \"label_size\": 28,\n",
    "    \"ticks_size\": 28,\n",
    "    \"annotation_size\": 18,\n",
    "}\n",
    "\n",
    "# Plotting data\n",
    "plot_percentage(fw, ax1, \"C\", title=r\"A\", fontsettings=fontsettings)\n",
    "plot_percentage(bw, ax2, \"C\", title=r\"B\", fontsettings=fontsettings)\n",
    "\n",
    "plot_percentage(fw, ax3, \"FPR\", title=r\"C\", fontsettings=fontsettings)\n",
    "plot_percentage(bw, ax4, \"FPR\", title=r\"D\", fontsettings=fontsettings)\n",
    "\n",
    "\n",
    "fig.legend(\n",
    "    [r\"$R_0$\", r\"$R_1$\", r\"$R_2$\", r\"$R_3$\"],  # Correct LaTeX formatted strings\n",
    "    loc=\"lower center\",\n",
    "    ncol=4,\n",
    "    fontsize=24,\n",
    "    bbox_to_anchor=(0.5, 0.001),\n",
    ")\n",
    "\n",
    "# Adjusting layout\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(hspace=0.15, bottom=0.08)\n",
    "fig.savefig(\n",
    "    \"./fig/template_false_rate_compare_valid.pdf\",\n",
    "    dpi=600,\n",
    "    bbox_inches=\"tight\",\n",
    "    pad_inches=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from _analysis._rule_app_analysis import load_results_from_json\n",
    "\n",
    "results = load_results_from_json(\"../../Data/Temp/Benchmark/raw_results.json\")\n",
    "\n",
    "valid = results[\"Test\"]\n",
    "\n",
    "valid_fw = valid[\"fw\"]\n",
    "valid_bw = valid[\"bw\"]\n",
    "fw = pd.DataFrame(valid_fw).T\n",
    "bw = pd.DataFrame(valid_bw).T\n",
    "fw.rename(\n",
    "    columns={\n",
    "        0: \"average_solution\",\n",
    "        # 1: r'\\mathcal(C)',\n",
    "        1: \"C\",\n",
    "        2: \"FPR\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "bw.rename(\n",
    "    columns={\n",
    "        0: \"average_solution\",\n",
    "        # 1: r'\\mathcal(C)',\n",
    "        1: \"C\",\n",
    "        2: \"FPR\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "fw[[\"Type\", \"Radii\"]] = fw.index.to_series().str.split(\"_\", expand=True)\n",
    "bw[[\"Type\", \"Radii\"]] = bw.index.to_series().str.split(\"_\", expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from _analysis._rule_app_analysis import plot_roc_curves\n",
    "\n",
    "plt.rc(\"text\", usetex=True)\n",
    "plt.rc(\"text.latex\", preamble=r\"\\usepackage{amsmath}\")  # Ensure amsmath is loaded\n",
    "fontsettings = {\n",
    "    \"title_size\": 24,\n",
    "    \"label_size\": 20,\n",
    "    \"ticks_size\": 20,\n",
    "    \"annotation_size\": 16,\n",
    "}\n",
    "fig, axs = plt.subplots(1, 2, figsize=(16, 8))\n",
    "plot_roc_curves(\n",
    "    fw,\n",
    "    axs[0],\n",
    "    selected_types=[\"Complete\", \"Expand\"],\n",
    "    fontsettings=fontsettings,\n",
    "    title=\"A\",\n",
    ")\n",
    "legend_handles = plot_roc_curves(\n",
    "    bw,\n",
    "    axs[1],\n",
    "    selected_types=[\"Complete\", \"Expand\"],\n",
    "    fontsettings=fontsettings,\n",
    "    title=\"B\",\n",
    ")\n",
    "\n",
    "fig.legend(\n",
    "    handles=legend_handles,\n",
    "    loc=\"lower center\",\n",
    "    fancybox=True,\n",
    "    title_fontsize=fontsettings[\"label_size\"],\n",
    "    fontsize=fontsettings[\"annotation_size\"],\n",
    "    ncol=3,\n",
    "    bbox_to_anchor=(0.5, 0.001),\n",
    ")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(hspace=0.15, wspace=0.2, bottom=0.2)\n",
    "fig.savefig(\"./fig/ROC_test.pdf\", dpi=600, bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G-mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from _analysis._rule_app_analysis import load_results_from_json\n",
    "\n",
    "results = load_results_from_json(\"../../Data/Temp/Benchmark/raw_results.json\")\n",
    "\n",
    "valid = results[\"Valid\"]\n",
    "\n",
    "valid_fw = valid[\"fw\"]\n",
    "valid_bw = valid[\"bw\"]\n",
    "fw = pd.DataFrame(valid_fw).T\n",
    "bw = pd.DataFrame(valid_bw).T\n",
    "fw.rename(\n",
    "    columns={\n",
    "        0: \"average_solution\",\n",
    "        # 1: r'\\mathcal(C)',\n",
    "        1: \"C\",\n",
    "        2: \"FPR\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "bw.rename(\n",
    "    columns={\n",
    "        0: \"average_solution\",\n",
    "        # 1: r'\\mathcal(C)',\n",
    "        1: \"C\",\n",
    "        2: \"FPR\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "fw[[\"Type\", \"Radii\"]] = fw.index.to_series().str.split(\"_\", expand=True)\n",
    "bw[[\"Type\", \"Radii\"]] = bw.index.to_series().str.split(\"_\", expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmean(tpr, fpr):\n",
    "    tnr = 1 - fpr  # True Negative Rate\n",
    "    g_mean = np.sqrt(tpr * tnr)\n",
    "    return g_mean\n",
    "\n",
    "\n",
    "# Calculate G-mean for each row and add it as a new column\n",
    "fw[\"G-mean-forward\"] = fw.apply(\n",
    "    lambda row: gmean(row[\"C\"] / 100, row[\"FPR\"] / 100), axis=1\n",
    ")\n",
    "bw[\"G-mean-backward\"] = bw.apply(\n",
    "    lambda row: gmean(row[\"C\"] / 100, row[\"FPR\"] / 100), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_result = pd.concat(\n",
    "    [fw[\"G-mean-forward\"], bw[[\"G-mean-backward\", \"Type\", \"Radii\"]]], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = pd.concat(\n",
    "    [fw[\"G-mean-forward\"], bw[[\"G-mean-backward\", \"Type\", \"Radii\"]]], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmean(tpr, fpr):\n",
    "    tnr = 1 - fpr  # True Negative Rate\n",
    "    g_mean = np.sqrt(tpr * tnr)\n",
    "    return g_mean\n",
    "\n",
    "\n",
    "# Calculate G-mean for each row and add it as a new column\n",
    "fw[\"G-mean\"] = fw.apply(lambda row: gmean(row[\"C\"] / 100, row[\"FPR\"] / 100), axis=1)\n",
    "bw[\"G-mean\"] = bw.apply(lambda row: gmean(row[\"C\"] / 100, row[\"FPR\"] / 100), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_mean_results = {}\n",
    "\n",
    "for type_, group in fw.groupby(\"Type\"):\n",
    "    tpr = (\n",
    "        group[\"C\"] / 100\n",
    "    )  # True Positive Rate (C is already in percentage, so divide by 100)\n",
    "    fpr = group[\"FPR\"] / 100  # False Positive Rate\n",
    "    tnr = 1 - fpr  # True Negative Rate\n",
    "    g_mean = np.sqrt(tpr * tnr).mean()  # Geometric Mean\n",
    "    g_mean_results[type_] = g_mean\n",
    "\n",
    "# Output the G-mean results for each Type\n",
    "g_mean_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Time processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def calculate_time_difference(log_file_path):\n",
    "    # Define the time format from the logs\n",
    "    time_format = \"%Y-%m-%d %H:%M:%S,%f\"\n",
    "\n",
    "    # Initialize variables to store timestamps\n",
    "    start_time = None\n",
    "    end_time = None\n",
    "\n",
    "    # Open and read the log file\n",
    "    with open(log_file_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            # Check if line contains the start process timestamp\n",
    "            if \"Start process\" in line:\n",
    "                timestamp_str = line.split(\" - \")[0]\n",
    "                start_time = datetime.strptime(timestamp_str, time_format)\n",
    "\n",
    "            # Check if line contains the forward prediction validation timestamp\n",
    "            elif \"Forward Prediction Validation\" in line:\n",
    "                timestamp_str = line.split(\" - \")[0]\n",
    "                end_time = datetime.strptime(timestamp_str, time_format)\n",
    "\n",
    "    # Ensure both timestamps are found\n",
    "    if start_time is None or end_time is None:\n",
    "        raise ValueError(\n",
    "            \"Timestamps for 'Start process' or 'Forward Prediction Validation' not found in the log file.\"\n",
    "        )\n",
    "\n",
    "    # Calculate the time difference\n",
    "    time_difference = end_time - start_time\n",
    "    total_seconds = time_difference.total_seconds()\n",
    "\n",
    "    return total_seconds\n",
    "\n",
    "\n",
    "# Example usage\n",
    "log_file_path = \"../../Data/Temp/Benchmark/Raw/Log/Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = [0, 1, 2, 3]\n",
    "result = []\n",
    "for i in radius:\n",
    "    try:\n",
    "        total_seconds = calculate_time_difference(\n",
    "            log_file_path=f\"{log_file_path}/r{i}.txt\"\n",
    "        )\n",
    "        result.append(total_seconds)\n",
    "    except:\n",
    "        result.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_times_compare = {\n",
    "    r\"$Q_{\\text{raw}}$\": [9169.663, 34687.0292, 212203.163, 450822.167],\n",
    "    r\"$Q_{\\text{complete}}$\": [10067.556, 36444.666, 213271.507, 458275.105],\n",
    "    r\"$Q_{\\text{expand}}$\": [10882.231, 36850.825, 215493.644, 465514.313],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_times_compare = {\n",
    "    r\"$Q_{\\text{raw}}$\": [9967.84, 34812.77, 214118.684, 460135.812],\n",
    "    r\"$Q_{\\text{complete}}$\": [5553.019, 17230.426, 170896.315, 450532.96],\n",
    "    r\"$Q_{\\text{expand}}$\": [11065.185, 36902.738, 215238.352, 466254.943],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _analysis._rule_app_analysis import plot_roc_curves, plot_processing_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(16, 8))\n",
    "plot_processing_times(valid_times_compare, ax=axs, title=\"A. Time benchmarking\")\n",
    "# plot_processing_times(test_times_compare, ax=axs[1], title = 'B')\n",
    "# fig.savefig('../../time_process_rule', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from _analysis._rule_app_analysis import load_results_from_json\n",
    "\n",
    "results = load_results_from_json(\"../../Data/Temp/Benchmark/raw_results.json\")\n",
    "\n",
    "valid = results[\"Valid\"]\n",
    "\n",
    "valid_fw = valid[\"fw\"]\n",
    "valid_bw = valid[\"bw\"]\n",
    "fw = pd.DataFrame(valid_fw).T\n",
    "bw = pd.DataFrame(valid_bw).T\n",
    "fw.rename(\n",
    "    columns={\n",
    "        0: \"average_solution\",\n",
    "        # 1: r'\\mathcal(C)',\n",
    "        1: \"C\",\n",
    "        2: \"FPR\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "bw.rename(\n",
    "    columns={\n",
    "        0: \"average_solution\",\n",
    "        # 1: r'\\mathcal(C)',\n",
    "        1: \"C\",\n",
    "        2: \"FPR\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "fw[[\"Type\", \"Radii\"]] = fw.index.to_series().str.split(\"_\", expand=True)\n",
    "bw[[\"Type\", \"Radii\"]] = bw.index.to_series().str.split(\"_\", expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have functions like plot_roc_curves and plot_processing_times already defined\n",
    "\n",
    "# Set up font settings and LaTeX for plot text\n",
    "plt.rc(\"text\", usetex=True)\n",
    "plt.rc(\"text.latex\", preamble=r\"\\usepackage{amsmath}\")  # Ensure amsmath is loaded\n",
    "fontsettings = {\n",
    "    \"title_size\": 24,\n",
    "    \"label_size\": 20,\n",
    "    \"ticks_size\": 20,\n",
    "    \"annotation_size\": 16,\n",
    "}\n",
    "\n",
    "# Create a 2x2 subplot layout\n",
    "fig, axs = plt.subplots(\n",
    "    2, 2, figsize=(14, 15)\n",
    ")  # Adjusted figure size for better layout\n",
    "\n",
    "# Plot time processing in the first row, spanning both columns\n",
    "axs[0, 0].remove()  # Remove the original first subplot in the first row\n",
    "axs[0, 1].remove()  # Remove the second subplot in the first row\n",
    "ax_time = fig.add_subplot(2, 2, (1, 2))  # Add a new subplot that spans the first row\n",
    "plot_processing_times(valid_times_compare, ax=ax_time, title=r\"A. Time Benchmarking\")\n",
    "\n",
    "# Plot ROC curves in the second row\n",
    "legend_handles_fw = plot_roc_curves(\n",
    "    fw,\n",
    "    axs[1, 0],\n",
    "    selected_types=[\"Complete\", \"Expand\"],\n",
    "    fontsettings=fontsettings,\n",
    "    title=r\"B. ROC Curves Validation\",\n",
    ")\n",
    "legend_handles_bw = plot_roc_curves(\n",
    "    bw,\n",
    "    axs[1, 1],\n",
    "    selected_types=[\"Complete\", \"Expand\"],\n",
    "    fontsettings=fontsettings,\n",
    "    title=r\"C. ROC Curves Test\",\n",
    ")\n",
    "\n",
    "# Combine legends from the ROC curves\n",
    "fig.legend(\n",
    "    handles=legend_handles_fw,\n",
    "    loc=\"lower center\",\n",
    "    fancybox=True,\n",
    "    title_fontsize=fontsettings[\"label_size\"],\n",
    "    fontsize=fontsettings[\"annotation_size\"],\n",
    "    ncol=3,\n",
    "    bbox_to_anchor=(0.5, 0.05),\n",
    "    prop={\"size\": 18},\n",
    ")\n",
    "\n",
    "# Adjust layout for better visual display\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(\n",
    "    hspace=0.15, wspace=0.2, bottom=0.17\n",
    ")  # Adjust spacing to accommodate the legend\n",
    "fig.savefig(\n",
    "    \"../../Docs/Analysis/fig/time_process_rule.pdf\",\n",
    "    dpi=600,\n",
    "    bbox_inches=\"tight\",\n",
    "    pad_inches=0,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SynITSG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
